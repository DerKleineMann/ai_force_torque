{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file regroups every kind of test for model training : \n",
    "- The first file & library imports are mandatory\n",
    "- The last exports are mandatory\n",
    "- The model training depends on the choice of algorithm\n",
    "\n",
    "There is an option to automate the training using togglable parameters \n",
    "Make sure to have set up the correct file structure using env_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ML Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set import parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_JSON_SUPPORTED = False\n",
    "DATA_FOLDER = \"versuch_f3\"\n",
    "VERSION_NB = 1\n",
    "FILENAME=\"model_training.ipynb\"\n",
    "DIRNAME=os.path.abspath(FILENAME).replace(FILENAME,'')\n",
    "DF_POINTS_RANGE = 11\n",
    "DF_POINTS_LENGTH = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from Feather file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/quentin/Documents/ai_force_torque/model_training.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quentin/Documents/ai_force_torque/model_training.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     new_df[\u001b[39m'\u001b[39m\u001b[39mcomdCart_z\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_df[\u001b[39m'\u001b[39m\u001b[39mcomdCart_z\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m375\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/quentin/Documents/ai_force_torque/model_training.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m new_df\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/quentin/Documents/ai_force_torque/model_training.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m transform_cart_pos(full_df)\u001b[39m.\u001b[39;49mto_numpy()\u001b[39m.\u001b[39;49mmin(),transform_cart_pos(full_df)\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensor/lib/python3.10/site-packages/numpy/core/_methods.py:45\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;49;00m, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# Load DataFrame\n",
    "full_df=pd.read_feather(DIRNAME+\"data/feather/\"+DATA_FOLDER+\"_\"+str(DF_POINTS_LENGTH)+\"_\"+str(VERSION_NB)+\".feather\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "full_df=full_df.drop([\"t_Sec\",\"t_nSec\",\"Fx1\",\"Fy1\",\"Fz1\",\"Tx1\",\"Ty1\",\"Tz1\"],axis=1)\n",
    "\n",
    "# Transform position from absolute to relative\n",
    "OFFSET_XYZ=[-578.6,261.4,-375]\n",
    "CARTESIAN_COLUMNS=['curCart_x','comdCart_x','curCart_y','comdCart_y','curCart_z','comdCart_z']\n",
    "for i in range(len(CARTESIAN_COLUMNS)):\n",
    "    full_df[CARTESIAN_COLUMNS[i]] = full_df[CARTESIAN_COLUMNS[i]] + OFFSET_XYZ[i//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "TEST_TRAIN_RATIO = 0.1\n",
    "VALID_TRAIN_RATIO = 0.2\n",
    "\n",
    "# Shuffle DataFrame\n",
    "shuffled_df=full_df.sample(frac=1,random_state=1)\n",
    "\n",
    "# X & Y datasets\n",
    "X = shuffled_df[['exT_A1','exT_A2','exT_A3','exT_A4','exT_A5','exT_A6','exT_A7',\n",
    "                'msT_A1','msT_A2','msT_A3','msT_A4','msT_A5','msT_A6','msT_A7',\n",
    "                'Fx','Fy','Fz','Tx','Ty','Tz']].to_numpy()\n",
    "Y = shuffled_df[['curCart_x','curCart_y','curCart_z']].to_numpy()\n",
    "\n",
    "# Train / Test / Validation dataset\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=TEST_TRAIN_RATIO, random_state=2)\n",
    "X_Train, X_Valid, Y_Train, Y_Valid = train_test_split(X_Train, Y_Train, test_size=VALID_TRAIN_RATIO, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-39.0410448, 80.4649761)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.min(), X_Train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - FFNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - CNN Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - FFNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 - RandomSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3 - Chained GridSearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
